{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ed3e340-17fd-4b71-a98e-c776aa45d053",
   "metadata": {},
   "source": [
    "\n",
    "# Get to Know a Dataset: CCRS MODIS Albedo at 250-m resolution and 10-day intervals\n",
    "\n",
    "This notebook serves as a guided tour of the [CCRS MODIS Albedo at 250-m resolution and 10-day intervals ](https://registry.opendata.aws/CCRSMODISAlbedo.yml) dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3779654-eeee-4708-83cf-245e03303475",
   "metadata": {},
   "source": [
    "\n",
    "### Q: How have you organized your dataset? Help us understand the key prefix structure of your S3 bucket.\n",
    "\n",
    "Key Prefixes would start with Bucketname, like ccrs-modis-albedo; there are subfolders starting from 2000 to 2024 , which corresponds to each year. The key prefixes could be  'ccrs-modis-albedo/2000/'\n",
    "\n",
    "A descriptive documentation prepared (https://github.com/OpsCCRS/AWS-Open-Data-Registry-Preparation/blob/main/CCRSMODISAlbedo/DescriptiveDocumentation_CCRSMODISAlbedo.pdf) describes how the data is organized, how users can find the data they need, and how users can use the data.\n",
    "\n",
    "Full documentation for this dataset can be found at: https://data.eodms-sgdot.nrcan-rncan.gc.ca/public/CCRS/Trishchenko_MODIS_Albedo/\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b47b69",
   "metadata": {},
   "source": [
    "### The codes for different scenarios are provided for users to access the data and use the data easily: \n",
    "\n",
    "    1.\tPrint all files in Bucket\n",
    "    2.\tPrint the names of subfolders and the number of files in each subfolder\n",
    "    3.\tPrint file names in one subfolder, for example, 2012\n",
    "    4.\tDownload files in a subfolder as a zip file (it is slow compared with downloading directly to a local drive without being zipped)\n",
    "    5.\tDownload a subfolder into a local folder\n",
    "    6.\tDownload a subfolder (2012) based on a shape file\n",
    "    7.\tDownload subfolders based on shape file\n",
    "    8.\tLoad files like BB_Albedo file and its State_Mask without downloading to the local\n",
    "    9.\tDownloaded files like BB_Albedo file and its State_Mask to the local and display \n",
    "    10.\tCreate false-color composite image of the area for mid-summer 2012 and show the corresponding values of shortwave (SW) broadband albedo\n",
    "    11.\tCreate a subset of false composite, display it and see the corresponding values of shortwave (SW) broadband albedo\n",
    "    12.\tCreate a false cloud free composite and save it in a local drive\n",
    "    13.\tCreate a subset of false composite and save it in a local drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65803f0",
   "metadata": {},
   "source": [
    "#### The user will need an Anaconda virtual environment with the following coomands:\n",
    "    First, start with Anaconda Prompt\n",
    "    conda create --name awstest jupyterlab ipykernel geopandas rasterio boto3\n",
    "    conda config --set ssl_verify false\n",
    "\n",
    "    or use the requirement.txt provided with the following commands\n",
    "    conda install pip\n",
    "    pip install -r requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54301d-a2dd-4e4c-9410-4dcd2a142724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config   \n",
    "\n",
    "import warnings\n",
    "import urllib3\n",
    "\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import time\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.warp import transform\n",
    "\n",
    "from rasterio.mask import mask\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52dc6d-99de-4fae-97af-c6c500a516be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#environment setting \n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\"\n",
    "os.environ[\"AWS_NO_SIGN_REQUEST\"] = \"YES\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b14ae10",
   "metadata": {},
   "source": [
    "#### Define the location of dataset, create boto3 S3 client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be33d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of the S3 bucket for this dataset\n",
    "bucket_name = 'ccrs-modis-albedo'\n",
    "\n",
    "# List the top level of the bucket using boto3. Because this is a public bucket, we don't need to sign requests.\n",
    "# Here we set the signature version to unsigned, which is required for public buckets.\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    config=Config(signature_version=UNSIGNED),\n",
    "    verify=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46a753-e433-457f-8954-03e5b9aaf095",
   "metadata": {},
   "source": [
    "#### 1. Print all files in Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b3079-4d51-4119-b8fd-a13d4597db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### print all files in the Bucket\n",
    "response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "for content in response.get('Contents', []):\n",
    "    print(content['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb9fa4d",
   "metadata": {},
   "source": [
    "#### 2. Print the names of subfolers and the number of files in each subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the name of subfolers and the number of files in each subfolder\n",
    "\n",
    "# Get all first-level subfolders\n",
    "subfolders = []\n",
    "continuation_token = None\n",
    "\n",
    "while True:\n",
    "    if continuation_token:\n",
    "        resp = s3.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix=\"\",\n",
    "            Delimiter=\"/\",\n",
    "            ContinuationToken=continuation_token\n",
    "        )\n",
    "    else:\n",
    "        resp = s3.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix=\"\",\n",
    "            Delimiter=\"/\"\n",
    "        )\n",
    "\n",
    "    # Add the prefixes (subfolders) found in this page\n",
    "    for cp in resp.get(\"CommonPrefixes\", []):\n",
    "        subfolders.append(cp[\"Prefix\"])\n",
    "\n",
    "    # Check if more pages exist\n",
    "    if resp.get(\"IsTruncated\"):\n",
    "        continuation_token = resp.get(\"NextContinuationToken\")\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Count files in each subfolder\n",
    "for folder in subfolders:\n",
    "    files = []\n",
    "    token = None\n",
    "    while True:\n",
    "        if token:\n",
    "            resp_files = s3.list_objects_v2(\n",
    "                Bucket=bucket_name,\n",
    "                Prefix=folder,\n",
    "                Delimiter=\"/\",\n",
    "                ContinuationToken=token\n",
    "            )\n",
    "        else:\n",
    "            resp_files = s3.list_objects_v2(\n",
    "                Bucket=bucket_name,\n",
    "                Prefix=folder,\n",
    "                Delimiter=\"/\"\n",
    "            )\n",
    "\n",
    "        # Add files (exclude subfolders)\n",
    "        for obj in resp_files.get('Contents', []):\n",
    "            files.append(obj['Key'].split('/')[-1])\n",
    "\n",
    "        if resp_files.get(\"IsTruncated\"):\n",
    "            token = resp_files.get(\"NextContinuationToken\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f\"Subfolder: {folder} -> Number of files: {len(files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4ac44-980a-466c-9bd7-bb95b00a176f",
   "metadata": {},
   "source": [
    "#### 3. Print file names in one subfolder, for example, 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a5f26-1997-4388-9ccc-d3c111a23f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## print file in /2012\n",
    "response3 = s3.list_objects_v2(\n",
    "    Bucket=bucket_name,\n",
    "    Prefix=\"2012/\",       # change subfolder for differenet years\n",
    "    Delimiter=\"/\"    \n",
    ")\n",
    "# Extract file names (exclude folders)\n",
    "file_names = [obj['Key'].split('/')[-1] for obj in response3.get('Contents', [])]\n",
    "\n",
    "print(\"Files in subfolder:\")\n",
    "for name in file_names:\n",
    "    print(name)\n",
    "\n",
    "# Print number of files\n",
    "print(\"Number of files:\", len(file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7607f1f-f79a-4c06-8797-34d482ad0846",
   "metadata": {},
   "source": [
    "#### 4. Download files in a subfolder as a zip file (it is slow compared with downloading directly to a local drive without being zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6435a-5dd8-41ed-8065-6ec7ec9425a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- download the subfolder as a zip file ---\n",
    "prefix = \"2000/\"           # subfolder to download\n",
    "zip_filename = \"2000.zip\"  # local zip file to create\n",
    "\n",
    "# List all files in the subfolder\n",
    "file_keys = []\n",
    "continuation_token = None\n",
    "\n",
    "while True:\n",
    "    if continuation_token:\n",
    "        resp = s3.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix=prefix,\n",
    "            Delimiter=\"/\",\n",
    "            ContinuationToken=continuation_token\n",
    "        )\n",
    "    else:\n",
    "        resp = s3.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix=prefix,\n",
    "            Delimiter=\"/\"\n",
    "        )\n",
    "    \n",
    "    # Collect file keys\n",
    "    for obj in resp.get('Contents', []):\n",
    "        file_keys.append(obj['Key'])\n",
    "    \n",
    "    if resp.get('IsTruncated'):\n",
    "        continuation_token = resp.get('NextContinuationToken')\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"Found {len(file_keys)} files in subfolder {prefix}\")\n",
    "\n",
    "# --- Download files with timing ---\n",
    "total_start = time.time()\n",
    "# --- Create ZIP ---\n",
    "with ZipFile(zip_filename, 'w') as zipf:\n",
    "    for key in file_keys:\n",
    "        file_name = key.split('/')[-1]  # remove folder prefix\n",
    "        # Download file content to memory\n",
    "        obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "        data = obj['Body'].read()\n",
    "        # Write into zip\n",
    "        zipf.writestr(file_name, data)\n",
    "        print(f\"Added {file_name} to {zip_filename}\")\n",
    "\n",
    "print(f\"Subfolder {prefix} downloaded as {zip_filename}\")\n",
    "\n",
    "total_end = time.time()\n",
    "\n",
    "print(f\"Total time: {total_end - total_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c5670-a98e-45dd-ad60-2e71eb8f4aa1",
   "metadata": {},
   "source": [
    "#### 5. Download a subfolder into a local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47404b41-2a04-458d-b5c3-865c50a2b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- download a subfolder into a local folder ---\n",
    "bucket = \"ccrs-modis-albedo\"\n",
    "prefix = \"2000/\"               # S3 subfolder to download\n",
    "local_dir = \"./2000_local\"     # Local folder to save files\n",
    "\n",
    "# Make sure local folder exists\n",
    "os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "# List all files in the subfolder\n",
    "file_keys = []\n",
    "continuation_token = None\n",
    "\n",
    "while True:\n",
    "    if continuation_token:\n",
    "        resp = s3.list_objects_v2(\n",
    "            Bucket=bucket,\n",
    "            Prefix=prefix,\n",
    "            Delimiter=\"/\",\n",
    "            ContinuationToken=continuation_token\n",
    "        )\n",
    "    else:\n",
    "        resp = s3.list_objects_v2(\n",
    "            Bucket=bucket,\n",
    "            Prefix=prefix,\n",
    "            Delimiter=\"/\"\n",
    "        )\n",
    "    \n",
    "    for obj in resp.get('Contents', []):\n",
    "        file_keys.append(obj['Key'])\n",
    "    \n",
    "    if resp.get('IsTruncated'):\n",
    "        continuation_token = resp.get('NextContinuationToken')\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(f\"Found {len(file_keys)} files in subfolder {prefix}\")\n",
    "\n",
    "# --- Download files with timing ---\n",
    "total_start = time.time()\n",
    "\n",
    "for key in file_keys:\n",
    "    file_name = key.split('/')[-1]              # remove folder prefix\n",
    "    local_path = os.path.join(local_dir, file_name)    \n",
    "   \n",
    "    s3.download_file(bucket, key, local_path)      \n",
    "    print(f\"Downloaded {file_name} to {local_path}\")\n",
    "\n",
    "total_end = time.time()\n",
    "print(f\"\\nAll files downloaded to {local_dir}\")\n",
    "print(f\"Total time: {total_end - total_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8d07c0-1c98-4d87-adea-6814526d2f8d",
   "metadata": {},
   "source": [
    "#### 6. Download a subfolder (2012) based on a shape file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d2094-9668-4ce6-8e5a-b69db88eea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"2012/\"\n",
    "example_key = \"2012/Terra_MODIS_SW_BB_Albedo.Noon_250m_20120711.tif\"\n",
    "shapefile = \"testarea.shp\" ## changet the shape file to yours\n",
    "# Construct HTTPS URL instead of /vsis3/\n",
    "example_url = f\"https://{bucket_name}.s3.ca-central-1.amazonaws.com/{example_key}\"\n",
    "\n",
    "## get crs informaiton for reproject shape file\n",
    "with rasterio.open(example_url) as src:\n",
    "    raster_crs = src.crs\n",
    "    # print(\"Raster CRS:\", raster_crs)\n",
    "## read shape file    \n",
    "gdf = gpd.read_file(shapefile)\n",
    "gdf = gdf.to_crs(raster_crs)\n",
    "geom = [mapping(g) for g in gdf.geometry]\n",
    "\n",
    "\n",
    "tif_list = []\n",
    "\n",
    "resp = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "for item in resp.get(\"Contents\", []):\n",
    "    key = item[\"Key\"]\n",
    "    if key.lower().endswith(\".tif\"):\n",
    "        tif_list.append(key)\n",
    "\n",
    "print(\"Found\", len(tif_list), \"files.\")\n",
    "\n",
    "out_dir = \"subset_2012\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "# --- Download files with timing ---\n",
    "total_start = time.time()\n",
    "\n",
    "for key in tif_list:\n",
    "    url = f\"https://{bucket_name}.s3.ca-central-1.amazonaws.com/{key}\"\n",
    "    out_path = os.path.join(out_dir, os.path.basename(key))\n",
    "\n",
    "    try:\n",
    "        with rasterio.open(url) as src:\n",
    "            out_image, out_transform = mask(src, geom, crop=True)\n",
    "            out_meta = src.meta.copy()\n",
    "            out_meta.update({\n",
    "                \"height\": out_image.shape[1],\n",
    "                \"width\": out_image.shape[2],\n",
    "                \"transform\": out_transform\n",
    "            })\n",
    "\n",
    "        with rasterio.open(out_path, \"w\", **out_meta) as dst:\n",
    "            dst.write(out_image)\n",
    "\n",
    "        print(\"Saved:\", out_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Failed:\", key, \"->\", e)\n",
    "\n",
    "total_end = time.time()\n",
    "print(f\"Total time: {total_end - total_start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba7171-2d31-400f-b275-e95c93d391a4",
   "metadata": {},
   "source": [
    "#### 7. Download subfolders based on a shape file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8f7e2-4dba-4ef9-a8d7-213222d91b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2012, 2015)   # 2012 to 2014, you can change to the range of years \n",
    "local_out_root = \"./subset_local\"   # folder to save clipped rasters\n",
    "shapefile = \"testarea.shp\"          # AOI, you can chanage your shape file\n",
    "raster_ext = (\".tif\",)\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(local_out_root, exist_ok=True)\n",
    "\n",
    "# Load AOI and prepare geometry\n",
    "gdf = gpd.read_file(shapefile)\n",
    "# Geometry will be reprojected later to match raster CRS\n",
    "geom = [mapping(gdf.geometry.union_all())]\n",
    "\n",
    "# --- Download files with timing ---\n",
    "total_start = time.time()\n",
    "# -----------------------------\n",
    "# Loop through years and download + clip\n",
    "# -----------------------------\n",
    "for year in years:\n",
    "    prefix = f\"{year}/\"\n",
    "    print(f\"\\n=== Processing year: {year} ===\")\n",
    "\n",
    "    # List all files in this subfolder\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    tif_keys = [item[\"Key\"] for item in response.get(\"Contents\", []) if item[\"Key\"].lower().endswith(raster_ext)]\n",
    "\n",
    "    # Local output folder for this year\n",
    "    out_folder = os.path.join(local_out_root, str(year))\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    for key in tif_keys:\n",
    "        # Construct HTTPS URL for raster\n",
    "        raster_url = f\"https://{bucket_name}.s3.ca-central-1.amazonaws.com/{key}\"\n",
    "        local_file = os.path.join(out_folder, os.path.basename(key))\n",
    "\n",
    "        try:\n",
    "            # Open raster from S3\n",
    "            with rasterio.open(raster_url) as src:\n",
    "                # Reproject AOI to raster CRS\n",
    "                geom_proj = gdf.to_crs(src.crs)\n",
    "                # geom_srs = [mapping(geom_proj.unary_union)]\n",
    "                geom_srs = [mapping(geom_proj.geometry.union_all())]\n",
    "\n",
    "                # Clip raster\n",
    "                clipped, out_transform = mask(src, geom_srs, crop=True)\n",
    "                out_meta = src.meta.copy()\n",
    "                out_meta.update({\n",
    "                    \"height\": clipped.shape[1],\n",
    "                    \"width\": clipped.shape[2],\n",
    "                    \"transform\": out_transform\n",
    "                })\n",
    "\n",
    "            # Save clipped raster locally\n",
    "            with rasterio.open(local_file, \"w\", **out_meta) as dst:\n",
    "                dst.write(clipped)\n",
    "\n",
    "            print(f\"Saved: {local_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed: {key} -> {e}\")\n",
    "\n",
    "print(\"\\n✔ All subfolders processed and saved locally.\")\n",
    "\n",
    "total_end = time.time()\n",
    "\n",
    "print(f\"Total time: {total_end - total_start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa1738-b2ee-4a09-9efa-1ba1b2031995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd7f4bcf-ec40-432f-a31f-4477efa205ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- DATA PROVIDER INSTRUCTIONS\n",
    "This section is meant to orient users of your dataset to the formats present in your dataset, particularly if your dataset includes formats that may be unfamiliar to a general data scientist audience. This section should include:\n",
    "\n",
    "1. Explanation of data format(s) (very common formats can be very briefly described, while less common\n",
    "   or domain specific formats should include more explanation as well as links to official documentation)\n",
    "2. Explanation of why the data format was chosen for your dataset\n",
    "3. Recommendations around software and tooling to work with this data format\n",
    "4. Explanation of any dataset-specific aspects to your usage of the format\n",
    "5. Description of AWS services that may be useful to users working with your data\n",
    "DATA PROVIDER INSTRUCTIONS -->\n",
    "\n",
    "### Q: What data formats are present in your dataset? What kinds of data are stored using these formats? Can you give any advice for how you work with these data formats?\n",
    "\n",
    "Our dataset comes as a set of Cloud Optimized GeoTIFF (COG) files grouped by years from 2000. \n",
    "Each year includes 36 composites (3 per month). Each composite group contains the following datasets: \n",
    "\n",
    "    Terra_MODIS_BX_Albedo.Noon_250m_YYYYMMDD.tif\n",
    "    Terra_MODIS_BX_BRDF.Norm_250m_YYYYMMDD.tif\n",
    "    Terra_MODIS_Index_BRDF.Norm_250m_YYYYMMDD.tif\n",
    "    Terra_MODIS_NDVI_250m_YYYYMMDD.tif\n",
    "    Terra_MODIS_VIS_BB_Albedo.Noon_250m_YYYYMMDD.tif\n",
    "    Terra_MODIS_NIR_BB_Albedo.Noon_250m_YYYYMMDD.tif\n",
    "    Terra_MODIS_SW_BB_Albedo.Noon_250m_YYYYMMDD.tif\n",
    "    Terra_MODIS_Snow_Fraction_250m_YYYYMMDD.tif\n",
    "    Terra_MODIS_Snow_GrainSize_1.0km_YYYYMMDD.tif\n",
    "    Terra_MODIS_State_Mask_250m_YYYYMMDD.tif\n",
    "where  YYYYMMDD labels year (YYYY), month (MM) and day (DD). <br>\n",
    "\n",
    "The reduced resolution (2.5km) false color browse images are also provided as Terra_MODIS_Albedo.Noon_Browse_FalseColor_RGB_YYYYMMDD_2.5km.tif\n",
    "\n",
    "COG datafiles can be processed using Python \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362bd15",
   "metadata": {},
   "source": [
    "### Q: Can you show us an example of downloading and loading data from your dataset?\n",
    "\n",
    "    Load and view Broadband albedo for mid-summer 2012.    \n",
    "    Load Terra_MODIS_SW_BB_Albedo.Noon_250m_20120711.tif    \n",
    "    Load state mask (to select cloud-free pixels in necessary)    \n",
    "    Load Terra_MODIS_State_Mask_250m_20120711.tif\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a0ca8-dcff-4a00-9b3d-064808157a47",
   "metadata": {},
   "source": [
    "#### 8. Load files like BB_Albedo file and its State_Mask without downloading to the local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dcfdf1-1b1c-4b74-a8cd-b0e019af0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "albedo_file = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_VIS_BB_Albedo.Noon_250m_20120711.tif\"\n",
    "mask_file   = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_State_Mask_250m_20120711.tif\"\n",
    "\n",
    "scale = 0.0001   # MODIS scale factor\n",
    "# -----------------------------------------------------\n",
    "# Load albedo\n",
    "# -----------------------------------------------------\n",
    "with rasterio.open(albedo_file) as src:\n",
    "    albedo = src.read(1).astype(\"float32\")\n",
    "    # albedo_nodata = src.nodata\n",
    "\n",
    "# Load state mask\n",
    "with rasterio.open(mask_file) as src_mask:\n",
    "    mask = src_mask.read(1).astype(\"uint8\")\n",
    "    # mask_nodata = src_mask.nodata\n",
    "\n",
    "# Apply scale factor\n",
    "albedo = albedo * scale\n",
    "# albedo[albedo > 1] = np.nan ## mask invalide pixels\n",
    "albedo[(albedo <= 0) | (albedo > 1)] = np.nan ## mask invalide pixels\n",
    "# -----------------------------------------------------\n",
    "# Cloud mask\n",
    "# Cloud 10 and nodata 255\n",
    "# -----------------------------------------------------\n",
    "cloud_free = ((mask != 10)|(mask!=255))\n",
    "albedo_masked = np.where(cloud_free, albedo, np.nan)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Plot\n",
    "# -----------------------------------------------------\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(albedo_masked, cmap=\"viridis\")\n",
    "plt.title(\"Cloud-Free Terra MODIS VIS BB Albedo (2012-07-11)\")\n",
    "plt.colorbar(label=\"Albedo\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddae0e-841b-4232-8143-62803b44e7a4",
   "metadata": {},
   "source": [
    "#### 9. Downloaded files like BB_Albedo file and its State_Mask to the local and display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f5012e-578a-4a43-9a7f-e553cea14ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"2012/Terra_MODIS_SW_BB_Albedo.Noon_250m_20120711.tif\"\n",
    "local_path = \"Terra_MODIS_SW_BB_Albedo.Noon_250m_20120711.tif\"\n",
    "\n",
    "s3.download_file(bucket_name, key, local_path)\n",
    "print(\"Downloaded:\", local_path)\n",
    "\n",
    "with rasterio.open(local_path) as src:\n",
    "    albedo = src.read(1).astype(\"float32\")   \n",
    "\n",
    "# Apply MODIS scale factor\n",
    "albedo = albedo * 0.0001\n",
    "\n",
    "# Replace invalid with NaN\n",
    "# albedo[albedo >1] = np.nan\n",
    "albedo[(albedo <= 0) | (albedo > 1)] = np.nan ## mask invalide pixels\n",
    "\n",
    "# Percentile stretch for better visualization\n",
    "low, high = np.nanpercentile(albedo, (2,98))\n",
    "albedo_stretched = np.clip((albedo - low) / (high - low), 0, 1)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "im = plt.imshow(albedo_stretched, cmap=\"viridis\")\n",
    "plt.title(\"MODIS SW Broadband Albedo (2012-07-11)\")\n",
    "plt.colorbar(im, label=\"Scaled Albedo\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95835aa3-8dbf-4248-afd3-4e569cb159ba",
   "metadata": {},
   "source": [
    "####  10. Create false-color composite image of the area for mid-summer 2012 and show the corresponding values of shortwave (SW) broadband albedo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717987e-c9c9-4c0f-9f2e-a8d761492625",
   "metadata": {},
   "source": [
    "\n",
    "### Q: A picture is worth a thousand words. Show us a visual (or several!) from your dataset that either illustrates something informative about your dataset, or that you think might excite someone to dig in further.\n",
    "\n",
    "Create false-color composite image of the area for mid-summer 2012 <br>\n",
    "    Load Terra_MODIS_B1_BRDF.Norm_250m_20000711.tif as BLUE(B) band <br>\n",
    "    Load Terra_MODIS_B2_BRDF.Norm_250m_20000711.tif as GREE(G) band <br>\n",
    "    Load Terra_MODIS_B6_BRDF.Norm_250m_20000711.tif as RED(R) band <br>\n",
    "This RGB picture will show the area covered by our dataset and the distribution of typical surface features (land, water, snow, vegetation, deserted areas)\n",
    "    Load Terra_MODIS_SW_BB_Albedo.Noon_250m_20120711.tif file to see the corresponding values of shortwave (SW) broadband albedo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False-color bands\n",
    "blue_file  = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B1_BRDF.Norm_250m_20120711.tif\"\n",
    "green_file = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B2_BRDF.Norm_250m_20120711.tif\"\n",
    "red_file   = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B6_BRDF.Norm_250m_20120711.tif\"\n",
    "mask_file   = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_State_Mask_250m_20120711.tif\"\n",
    "\n",
    "# SW BB Albedo\n",
    "albedo_file = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_SW_BB_Albedo.Noon_250m_20120711.tif\"\n",
    "scale = 0.0001  # scale factor for albedo\n",
    "\n",
    "# -----------------------------\n",
    "# Function to read raster\n",
    "# -----------------------------\n",
    "def read_raster(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        arr = src.read(1).astype('float32')\n",
    "        if src.nodata is not None:\n",
    "            arr[arr == src.nodata] = np.nan\n",
    "    return arr\n",
    "# -----------------------------\n",
    "# Function to read raster with crs and transform\n",
    "# -----------------------------\n",
    "def read_raster2(file_path):   \n",
    "    with rasterio.open(file_path) as src:\n",
    "        data = src.read(1).astype('float32')\n",
    "        if src.nodata is not None:\n",
    "            data[data == src.nodata] = np.nan\n",
    "        crs = src.crs\n",
    "        transform = src.transform\n",
    "    return data, crs, transform\n",
    "\n",
    "# -----------------------------\n",
    "# Read bands\n",
    "# -----------------------------\n",
    "B = read_raster(blue_file)* scale\n",
    "G = read_raster(green_file)* scale\n",
    "R = read_raster(red_file)* scale\n",
    "# B*=scale\n",
    "B[(B <= 0) | (B > 1)] = np.nan ## mask invalid pixels\n",
    "R[(R <= 0) | (R > 1)] = np.nan ## mask invalid pixels\n",
    "G[(G <= 0) | (G > 1)] = np.nan ## mask invalid pixels\n",
    "\n",
    "\n",
    "# Load state mask\n",
    "with rasterio.open(mask_file) as src_mask:\n",
    "    mask = src_mask.read(1).astype(\"uint8\")\n",
    "    # mask_nodata = src_mask.nodata\n",
    "\n",
    "albedo = read_raster(albedo_file) * scale  # apply scale factor\n",
    "# albedo[albedo > 1] = np.nan ## mask the value greater than 1\n",
    "albedo[(albedo <= 0) | (albedo > 1)] = np.nan ## mask invalide pixels\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Cloud mask\n",
    "# Cloud 10 and nodata 255\n",
    "# -----------------------------------------------------\n",
    "cloud_free = ((mask != 10)|(mask!=255))\n",
    "\n",
    "albedo_masked = np.where(cloud_free, albedo, np.nan)\n",
    "R_masked = np.where(cloud_free, R, np.nan)\n",
    "G_masked = np.where(cloud_free, G, np.nan)\n",
    "B_masked = np.where(cloud_free, B, np.nan)\n",
    "\n",
    "# -----------------------------\n",
    "# Stack RGB for false-color\n",
    "# -----------------------------\n",
    "# Normalize each band to 0-1 for display\n",
    "def normalize(array):\n",
    "    min_val = np.nanpercentile(array, 2)\n",
    "    max_val = np.nanpercentile(array, 98)\n",
    "    return np.clip((array - min_val) / (max_val - min_val), 0, 1)\n",
    "\n",
    "rgb_norm = np.dstack([\n",
    "    normalize(R_masked),  # RED band\n",
    "    normalize(G_masked),  # GREEN band\n",
    "    normalize(B_masked)   # BLUE band\n",
    "])\n",
    "\n",
    "# -----------------------------\n",
    "# Plot RGB composite\n",
    "# -----------------------------\n",
    "# print ('plotting')\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(rgb_norm)\n",
    "plt.title(\"MODIS False-Color Composite (B6->R, B2->G, B1->B) 2012-07-11\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Plot SW BB Albedo\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(albedo, cmap='viridis')\n",
    "plt.title(\"Terra MODIS SW Broadband Albedo 2012-07-11\")\n",
    "plt.colorbar(label='Albedo')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf5cdf3",
   "metadata": {},
   "source": [
    "#### 11. Create a subset of false composite, display it and see the corresponding values of shortwave (SW) broadband albedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef33976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False-color bands\n",
    "\n",
    "blue_file  = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B1_BRDF.Norm_250m_20120711.tif\"\n",
    "green_file = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B2_BRDF.Norm_250m_20120711.tif\"\n",
    "red_file   = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B6_BRDF.Norm_250m_20120711.tif\"\n",
    "mask_file   = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_State_Mask_250m_20120711.tif\"\n",
    "\n",
    "# SW BB Albedo\n",
    "albedo_file = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_SW_BB_Albedo.Noon_250m_20120711.tif\"\n",
    "\n",
    "scale = 0.0001\n",
    "\n",
    "# -----------------------------\n",
    "# Define lat/lon bounding box (subset)\n",
    "# -----------------------------\n",
    "lon_min, lon_max = -101.0, -95.0  # degrees\n",
    "lat_min, lat_max = 46.0, 50.0      # degrees\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: Reproject bounding box to raster CRS\n",
    "# -----------------------------\n",
    "def reproject_bounds_to_raster_crs(lat_min, lat_max, lon_min, lon_max, raster_path):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster_crs = src.crs\n",
    "\n",
    "    # Input coordinates in geographic CRS (EPSG:4326)\n",
    "    xs = [lon_min, lon_max, lon_min, lon_max]\n",
    "    ys = [lat_min, lat_min, lat_max, lat_max]\n",
    "\n",
    "    # Transform to raster CRS\n",
    "    xr, yr = transform(\"EPSG:4326\", raster_crs, xs, ys)\n",
    "\n",
    "    # Return new projected bounds\n",
    "    return min(xr), min(yr), max(xr), max(yr), raster_crs\n",
    "\n",
    "# -----------------------------\n",
    "# Reproject geog → raster CRS\n",
    "# -----------------------------\n",
    "xmin, ymin, xmax, ymax, raster_crs = reproject_bounds_to_raster_crs(\n",
    "    lat_min, lat_max, lon_min, lon_max, red_file\n",
    ")\n",
    "# -----------------------------\n",
    "# Function to read raster subset using projected window\n",
    "# -----------------------------\n",
    "def read_subset(path, xmin, ymin, xmax, ymax, return_transform=False):\n",
    "    with rasterio.open(path) as src:\n",
    "        window = from_bounds(xmin, ymin, xmax, ymax, transform=src.transform)\n",
    "        data = src.read(1, window=window).astype(\"float32\")\n",
    "\n",
    "        # Generate correct subset transform\n",
    "        transform = src.window_transform(window)\n",
    "\n",
    "        if return_transform:\n",
    "            return data, transform, src.crs\n",
    "        return data\n",
    "# -----------------------------\n",
    "# Read bands using correct projected window\n",
    "# -----------------------------\n",
    "R, subset_transform, subset_crs = read_subset(red_file, xmin, ymin, xmax, ymax, return_transform=True)\n",
    "G = read_subset(green_file, xmin, ymin, xmax, ymax)\n",
    "B = read_subset(blue_file, xmin, ymin, xmax, ymax)\n",
    "MASK = read_subset(mask_file, xmin, ymin, xmax, ymax)\n",
    "albedo = read_subset(albedo_file, xmin, ymin, xmax, ymax)\n",
    "\n",
    "  # apply scale factor\n",
    "R *= scale\n",
    "G *= scale\n",
    "B*=scale\n",
    "albedo*=scale\n",
    "# albedo[albedo > 1] = np.nan\n",
    "albedo[(albedo <= 0) | (albedo > 1)] = np.nan ## mask invalide pixels\n",
    "B[(B <= 0) | (B > 1)] = np.nan ## mask invalid pixels\n",
    "R[(R <= 0) | (R > 1)] = np.nan ## mask invalid pixels\n",
    "G[(G <= 0) | (G > 1)] = np.nan ## mask invalid pixels\n",
    "\n",
    "# -----------------------------\n",
    "# Apply cloud mask: only cloud-free pixels (cloud:=10, nodata: 255)\n",
    "# -----------------------------\n",
    "\n",
    "cloud_free = ((MASK != 10)|(MASK != 255))\n",
    "\n",
    "# Mask RGB bands\n",
    "R_masked = np.where(cloud_free, R, np.nan)\n",
    "G_masked = np.where(cloud_free, G, np.nan)\n",
    "B_masked = np.where(cloud_free, B, np.nan)\n",
    "\n",
    "# # Mask albedo\n",
    "albedo_masked = np.where(cloud_free, albedo, np.nan)\n",
    "\n",
    "# -----------------------------\n",
    "# Stack RGB for false-color\n",
    "# -----------------------------\n",
    "def normalize(array):\n",
    "    min_val = np.nanpercentile(array, 2)\n",
    "    max_val = np.nanpercentile(array, 98)\n",
    "    return np.clip((array - min_val) / (max_val - min_val), 0, 1)\n",
    "\n",
    "rgb = np.dstack([\n",
    "    normalize(R_masked),  # RED\n",
    "    normalize(G_masked),  # GREEN\n",
    "    normalize(B_masked)   # BLUE\n",
    "])\n",
    "print (rgb.shape)\n",
    "\n",
    "# -----------------------------\n",
    "# # Plot RGB\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(rgb)\n",
    "plt.title(\"MODIS False-Color Composite (Subset, Cloud-Free) 2012-07-11\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# # -----------------------------\n",
    "# # Plot Albedo\n",
    "# # -----------------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(albedo_masked, cmap='viridis')\n",
    "# plt.imshow(aldedo_stretched, cmap='viridis')\n",
    "plt.title(\"Terra MODIS SW Broadband Albedo (Subset, Cloud-Free) 2012-07-11\")\n",
    "plt.colorbar(label='Albedo')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bd9347",
   "metadata": {},
   "source": [
    "#### 12. Create a false cloud free composite and save it in a local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False-color bands\n",
    "blue_file  = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B1_BRDF.Norm_250m_20120711.tif\"\n",
    "green_file = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B2_BRDF.Norm_250m_20120711.tif\"\n",
    "red_file   = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B6_BRDF.Norm_250m_20120711.tif\"\n",
    "mask_file   = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_State_Mask_250m_20120711.tif\"\n",
    "\n",
    "scale = 0.0001  # scale factor for albedo\n",
    "\n",
    "# -----------------------------\n",
    "# Function to read raster\n",
    "# -----------------------------\n",
    "def read_raster(path):\n",
    "    with rasterio.open(path) as src:\n",
    "        arr = src.read(1).astype('float32')\n",
    "        if src.nodata is not None:\n",
    "            arr[arr == src.nodata] = np.nan\n",
    "    return arr\n",
    "\n",
    "# -----------------------------\n",
    "# Function to read raster to return crs and transform\n",
    "# -----------------------------\n",
    "\n",
    "def read_raster2(file_path):\n",
    "     \n",
    "    with rasterio.open(file_path) as src:\n",
    "        data = src.read(1).astype('float32')\n",
    "        # if src.nodata is not None:\n",
    "        #     data[data == src.nodata] = np.nan\n",
    "        crs = src.crs\n",
    "        transform = src.transform\n",
    "    return data, crs, transform\n",
    "\n",
    "# -----------------------------\n",
    "# Read bands\n",
    "# -----------------------------\n",
    "# B = read_raster(blue_file)* scale\n",
    "B, B_CRS, B_transform = read_raster2(blue_file)\n",
    "G = read_raster(green_file)* scale\n",
    "R = read_raster(red_file)* scale\n",
    "B*=scale\n",
    "\n",
    "\n",
    "# Load state mask\n",
    "with rasterio.open(mask_file) as src_mask:\n",
    "    mask = src_mask.read(1).astype(\"uint8\")\n",
    "    # mask_nodata = src_mask.nodata\n",
    "\n",
    "albedo = read_raster(albedo_file) * scale  # apply scale factor\n",
    "\n",
    "# albedo[albedo > 1] = np.nan\n",
    "albedo[(albedo <= 0) | (albedo > 1)] = np.nan ## mask invalide pixels\n",
    "B[(B <= 0) | (B > 1)] = np.nan ## mask invalid pixels\n",
    "R[(R <= 0) | (R > 1)] = np.nan ## mask invalid pixels\n",
    "G[(G <= 0) | (G > 1)] = np.nan ## mask invalid pixels\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Cloud mask\n",
    "# Cloud 10 and nodata 255\n",
    "# -----------------------------------------------------\n",
    "cloud_free = ((mask != 10)|(mask!=255))\n",
    "\n",
    "albedo_masked = np.where(cloud_free, albedo, np.nan)\n",
    "R_masked = np.where(cloud_free, R, np.nan)\n",
    "G_masked = np.where(cloud_free, G, np.nan)\n",
    "B_masked = np.where(cloud_free, B, np.nan)\n",
    "\n",
    "\n",
    "### for creating rgb composite\n",
    "\n",
    "rgb = np.dstack([\n",
    "    R_masked,  # RED band\n",
    "    G_masked,  # GREEN band\n",
    "    B_masked   # BLUE band\n",
    "])\n",
    "# # -----------------------------\n",
    "out_file = \"MODIS_BRDF_Norm_RGB_20120711_cloudfree.tif\"\n",
    "\n",
    "with rasterio.open(\n",
    "    out_file,\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=rgb.shape[0],\n",
    "    width=rgb.shape[1],\n",
    "    count=3,\n",
    "    dtype=\"float32\",\n",
    "    transform=B_transform,\n",
    "    crs=B_CRS,\n",
    ") as dst:\n",
    "    dst.write(rgb[:, :, 0], 1)\n",
    "    dst.write(rgb[:, :, 1], 2)\n",
    "    dst.write(rgb[:, :, 2], 3)\n",
    "\n",
    "print(f\"Saved RGB subset to: {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303cbc82",
   "metadata": {},
   "source": [
    "#### 13. Create a subset of false composite and save it in a local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df75c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# False-color bands\n",
    "\n",
    "blue_file  = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B1_BRDF.Norm_250m_20120711.tif\"\n",
    "green_file = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B2_BRDF.Norm_250m_20120711.tif\"\n",
    "red_file   = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_B6_BRDF.Norm_250m_20120711.tif\"\n",
    "mask_file   = f\"https://ccrs-modis-albedo.s3.ca-central-1.amazonaws.com/2012/Terra_MODIS_State_Mask_250m_20120711.tif\"\n",
    "\n",
    "scale = 0.0001\n",
    "\n",
    "# -----------------------------\n",
    "# Define lat/lon bounding box (subset)\n",
    "# -----------------------------\n",
    "lon_min, lon_max = -101.0, -95.0  # degrees\n",
    "lat_min, lat_max = 46.0, 50.0      # degrees\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: Reproject bounding box to raster CRS\n",
    "# -----------------------------\n",
    "def reproject_bounds_to_raster_crs(lat_min, lat_max, lon_min, lon_max, raster_path):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        raster_crs = src.crs\n",
    "\n",
    "    # Input coordinates in geographic CRS (EPSG:4326)\n",
    "    xs = [lon_min, lon_max, lon_min, lon_max]\n",
    "    ys = [lat_min, lat_min, lat_max, lat_max]\n",
    "\n",
    "    # Transform to raster CRS\n",
    "    xr, yr = transform(\"EPSG:4326\", raster_crs, xs, ys)\n",
    "\n",
    "    # Return new projected bounds\n",
    "    return min(xr), min(yr), max(xr), max(yr), raster_crs\n",
    "\n",
    "# -----------------------------\n",
    "# Reproject geog → raster CRS\n",
    "# -----------------------------\n",
    "xmin, ymin, xmax, ymax, raster_crs = reproject_bounds_to_raster_crs(\n",
    "    lat_min, lat_max, lon_min, lon_max, red_file\n",
    ")\n",
    "# -----------------------------\n",
    "# Function to read raster subset using projected window\n",
    "# -----------------------------\n",
    "def read_subset(path, xmin, ymin, xmax, ymax, return_transform=False):\n",
    "    with rasterio.open(path) as src:\n",
    "        window = from_bounds(xmin, ymin, xmax, ymax, transform=src.transform)\n",
    "        data = src.read(1, window=window).astype(\"float32\")\n",
    "\n",
    "        # Generate correct subset transform\n",
    "        transform = src.window_transform(window)\n",
    "\n",
    "        if return_transform:\n",
    "            return data, transform, src.crs\n",
    "        return data\n",
    "# -----------------------------\n",
    "# Read bands using correct projected window\n",
    "# -----------------------------\n",
    "R, subset_transform, subset_crs = read_subset(red_file, xmin, ymin, xmax, ymax, return_transform=True)\n",
    "G = read_subset(green_file, xmin, ymin, xmax, ymax)\n",
    "B = read_subset(blue_file, xmin, ymin, xmax, ymax)\n",
    "MASK = read_subset(mask_file, xmin, ymin, xmax, ymax)\n",
    "\n",
    "  # apply scale factor\n",
    "R *= scale\n",
    "G *= scale\n",
    "B*=scale\n",
    "\n",
    "\n",
    "B[(B <= 0) | (B > 1)] = np.nan ## mask invalid pixels\n",
    "R[(R <= 0) | (R > 1)] = np.nan ## mask invalid pixels\n",
    "G[(G <= 0) | (G > 1)] = np.nan ## mask invalid pixels\n",
    "\n",
    "# -----------------------------\n",
    "# Apply cloud mask: only cloud-free pixels (mask==10)\n",
    "# -----------------------------\n",
    "# # cloud_free = (mask != 10)\n",
    "cloud_free = ((MASK != 10)|(MASK != 255))\n",
    "\n",
    "# Mask RGB bands\n",
    "R_masked = np.where(cloud_free, R, np.nan)\n",
    "G_masked = np.where(cloud_free, G, np.nan)\n",
    "B_masked = np.where(cloud_free, B, np.nan)\n",
    "\n",
    "\n",
    "rgb = np.dstack([\n",
    "    R_masked,  # RED\n",
    "    G_masked,  # GREEN\n",
    "   B_masked   # BLUE\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Save RGB as a 3-band GeoTIFF\n",
    "# -----------------------------\n",
    "out_file = \"MODIS_RGB_Subset_20120711.tif\"\n",
    "\n",
    "\n",
    "with rasterio.open(\n",
    "    out_file,\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=rgb.shape[0],\n",
    "    width=rgb.shape[1],\n",
    "    count=3,\n",
    "    dtype=\"float32\",\n",
    "    transform=subset_transform,\n",
    "    crs=subset_crs,\n",
    ") as dst:\n",
    "    dst.write(rgb[:, :, 0], 1)\n",
    "    dst.write(rgb[:, :, 1], 2)\n",
    "    dst.write(rgb[:, :, 2], 3)\n",
    "\n",
    "print(f\"Saved RGB subset to: {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183c8b85-ed1c-4f2c-bd0e-fbfbc67c4723",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Q: What is one question that you have answered using these data? Can you show us how you came to that answer?\n",
    "\n",
    "These data have been used to study the Minimum Snow/Ice (MSI) extent variations, quantifying the rate of declining the Artic and alpine glaciated areas of North America, as well as climate impacts of radiative forcing driven by agricultural land-use and land-cover changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf645724-3108-4ada-a832-10b3431eb8e2",
   "metadata": {},
   "source": [
    "\n",
    "### Q: What is one unanswered question that you think could be answered using these data? Do you have any recommendations or advice for someone wanting to answer this question?\n",
    "\n",
    "What new can we learn from these data about reflectance and albedo for water/ocean surface. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
